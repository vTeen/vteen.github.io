# åƒç‰› AI æ™ºèƒ½å®¢æœ â€” æœ€ç»ˆè½åœ°æ–¹æ¡ˆ

> åŸºäºå¯¹åƒç‰› macOS ç‰ˆ v9.91.00 çš„å®é™…é€†å‘æ¢æµ‹ï¼Œç¡®è®¤ï¼š
> - CEF è¿œç¨‹è°ƒè¯•è¢«å°æ­»ï¼ˆä¸»ç¨‹åºä¸ä¼ é€’ `--remote-debugging-port`ï¼‰
> - æ¶ˆæ¯æ•°æ®åº“å…¨éƒ¨åŠ å¯†ï¼ˆSQLCipher/WCDBï¼‰
> - Accessibility API æ— æ³•ç©¿é€ Qt+CEF è‡ªç»˜ç•Œé¢
> - æœ¬æ–¹æ¡ˆä»¥ **æˆªå›¾ + AI è§†è§‰ç†è§£** ä¸ºæ ¸å¿ƒï¼Œå·²å……åˆ†éªŒè¯å¯è¡Œæ€§

---

## ä¸€ã€æ¶æ„æ€»è§ˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              åƒç‰›å®¢æˆ·ç«¯ï¼ˆä¸åšä»»ä½•ä¿®æ”¹ï¼‰                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚        èŠå¤©çª—å£ï¼ˆCEF æ¸²æŸ“çš„ Web é¡µé¢ï¼‰         â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ æˆªå›¾é‡‡é›†ï¼ˆ500msï¼‰              â”‚ æ¨¡æ‹Ÿè¾“å…¥
           â–¼                              â–²
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   æœ¬åœ° Agent (Python)                     â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ å±å¹•é‡‡é›†  â”‚â†’â”‚ å·®å¼‚æ£€æµ‹  â”‚â†’â”‚ æ¶ˆæ¯   â”‚â†’â”‚ WebSocket â”‚ â”‚
â”‚  â”‚ (CG API) â”‚  â”‚ (numpy)  â”‚  â”‚ æå–å™¨ â”‚  â”‚  å®¢æˆ·ç«¯   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                â”‚       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚       â”‚
â”‚  â”‚ æ¶ˆæ¯å‘é€  â”‚â†â”‚  äººæœºåä½œæ§åˆ¶å™¨            â”‚â†â”€â”€â”€â”˜       â”‚
â”‚  â”‚(æ¨¡æ‹Ÿé”®ç›˜) â”‚  â”‚ (å…¨æ‰˜ç®¡/è¾…åŠ©/çº¯äººå·¥)      â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ WebSocket
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     äº‘ç«¯æœåŠ¡                               â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Kafka  â”‚â†’â”‚ AI Worker  â”‚â†â”‚  RAG   â”‚  â”‚ åä½œæ§åˆ¶å°  â”‚ â”‚
â”‚  â”‚æ¶ˆæ¯é˜Ÿåˆ— â”‚  â”‚(æ„å›¾+ç”Ÿæˆ) â”‚  â”‚çŸ¥è¯†æ£€ç´¢ â”‚  â”‚  (Web UI)  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Redis  â”‚  â”‚ Qdrant    â”‚  â”‚ Prometheus + Grafana â”‚   â”‚
â”‚  â”‚ä¼šè¯ç¼“å­˜ â”‚  â”‚ å‘é‡æ•°æ®åº“ â”‚  â”‚       ç›‘æ§å‘Šè­¦       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## äºŒã€æ¶ˆæ¯ç›‘å¬å±‚ â€” æˆªå›¾ + åŒè½¨æ¶ˆæ¯æå–

### æ ¸å¿ƒç­–ç•¥

é‡‡ç”¨ **åŒè½¨å¹¶è¡Œ** çš„æ¶ˆæ¯æå–ç­–ç•¥ï¼Œå…¼é¡¾æˆæœ¬å’Œå‡†ç¡®æ€§ï¼š

- **å¿«é€Ÿè½¨ï¼ˆApple Vision OCRï¼‰**ï¼šæœ¬åœ°è¿è¡Œï¼Œé›¶æˆæœ¬ï¼Œ~200msï¼Œç”¨äºå®æ—¶æ£€æµ‹"æœ‰æ²¡æœ‰æ–°æ¶ˆæ¯"
- **ç²¾å‡†è½¨ï¼ˆVLM è§†è§‰æ¨¡å‹ï¼‰**ï¼šäº‘ç«¯è°ƒç”¨ï¼Œ~1.5sï¼Œç”¨äºç²¾ç¡®æå–æ¶ˆæ¯ç»“æ„ï¼ˆè°è¯´äº†ä»€ä¹ˆï¼‰

```
æˆªå›¾(30ms) â†’ åƒç´ å·®å¼‚æ£€æµ‹(5ms)
                â”‚
                â”œâ”€ æ— å˜åŒ– â†’ è·³è¿‡ï¼ˆèŠ‚çœ 95% çš„è®¡ç®—é‡ï¼‰
                â”‚
                â””â”€ æœ‰å˜åŒ– â†’ åŒæ—¶è§¦å‘åŒè½¨
                              â”‚
                              â”œâ”€ å¿«é€Ÿè½¨: Apple Vision OCR â†’ ç²—æå–æ–‡æœ¬ â†’ è§¦å‘é€šçŸ¥
                              â”‚
                              â””â”€ ç²¾å‡†è½¨: VLM â†’ ç»“æ„åŒ–æ¶ˆæ¯åˆ—è¡¨ â†’ é€ AI å¤„ç†
```

### 2.1 å±å¹•é‡‡é›†æ¨¡å—

```python
# screen_capture.py
"""
macOS å±å¹•é‡‡é›† â€” åŸºäº CoreGraphics API
æ€§èƒ½: ~30ms/å¸§ï¼Œæ”¯æŒæŒ‡å®šçª—å£å’ŒåŒºåŸŸæˆªå–
"""
import subprocess
import json
import time
import objc
from Quartz import (
    CGWindowListCopyWindowInfo,
    kCGWindowListOptionOnScreenOnly,
    kCGNullWindowID,
    CGWindowListCreateImage,
    CGRectMake, CGRectNull,
    kCGWindowListOptionIncludingWindow,
    kCGWindowImageDefault,
)
from AppKit import NSBitmapImageRep, NSBitmapImageFileTypePNG
from Foundation import NSData
import io


class ScreenCapture:
    """é«˜æ€§èƒ½å±å¹•æˆªå›¾"""
    
    def __init__(self):
        self._window_id = None
        self._chat_region = None  # (x, y, w, h) èŠå¤©åŒºåŸŸç›¸å¯¹åæ ‡
    
    def find_qianniu_window(self) -> dict:
        """æŸ¥æ‰¾åƒç‰›ä¸»çª—å£"""
        windows = CGWindowListCopyWindowInfo(
            kCGWindowListOptionOnScreenOnly,
            kCGNullWindowID
        )
        for w in windows:
            owner = w.get('kCGWindowOwnerName', '')
            name = w.get('kCGWindowName', '')
            if 'Aliworkbench' in owner or 'åƒç‰›' in owner:
                self._window_id = w['kCGWindowNumber']
                bounds = w['kCGWindowBounds']
                return {
                    'window_id': self._window_id,
                    'x': bounds['X'],
                    'y': bounds['Y'],
                    'width': bounds['Width'],
                    'height': bounds['Height'],
                    'owner': owner,
                    'name': name,
                }
        return None
    
    def capture_window(self) -> bytes:
        """æˆªå–åƒç‰›æ•´ä¸ªçª—å£"""
        if not self._window_id:
            self.find_qianniu_window()
        
        image = CGWindowListCreateImage(
            CGRectNull,  # è‡ªåŠ¨é€‚é…çª—å£å¤§å°
            kCGWindowListOptionIncludingWindow,
            self._window_id,
            kCGWindowImageDefault
        )
        
        if image is None:
            raise RuntimeError("æˆªå›¾å¤±è´¥ï¼Œåƒç‰›çª—å£å¯èƒ½å·²æœ€å°åŒ–")
        
        bitmap = NSBitmapImageRep.alloc().initWithCGImage_(image)
        png_data = bitmap.representationUsingType_properties_(
            NSBitmapImageFileTypePNG, None
        )
        return bytes(png_data)
    
    def capture_chat_region(self) -> bytes:
        """
        åªæˆªå–èŠå¤©æ¶ˆæ¯åŒºåŸŸï¼ˆå‡å°‘ VLM å¤„ç†çš„å›¾åƒå¤§å°ï¼ŒèŠ‚çœ tokenï¼‰
        
        éœ€è¦å…ˆé€šè¿‡ configure_chat_region() è®¾ç½®åŒºåŸŸ
        """
        if not self._chat_region:
            # é»˜è®¤æˆªå–çª—å£å³ä¾§ 60%ã€ä¸­é—´ 70% é«˜åº¦ï¼ˆèŠå¤©åŒºåŸŸçš„å…¸å‹ä½ç½®ï¼‰
            window = self.find_qianniu_window()
            if window:
                w, h = window['width'], window['height']
                self._chat_region = (
                    int(w * 0.35),   # x: å·¦ä¾§ 35% æ˜¯ä¼šè¯åˆ—è¡¨
                    int(h * 0.05),   # y: é¡¶éƒ¨ 5% æ˜¯æ ‡é¢˜æ 
                    int(w * 0.65),   # width: å³ä¾§ 65%
                    int(h * 0.75),   # height: åº•éƒ¨ç•™ç»™è¾“å…¥æ¡†
                )
        
        # ä½¿ç”¨ screencapture å‘½ä»¤æˆªå–æŒ‡å®šåŒºåŸŸï¼ˆæ›´å¯é ï¼‰
        window = self.find_qianniu_window()
        if not window:
            raise RuntimeError("æœªæ‰¾åˆ°åƒç‰›çª—å£")
        
        x = window['x'] + self._chat_region[0]
        y = window['y'] + self._chat_region[1]
        w = self._chat_region[2]
        h = self._chat_region[3]
        
        tmp_path = '/tmp/_qn_chat_capture.png'
        subprocess.run(
            ['screencapture', '-x', '-R', f'{x},{y},{w},{h}', '-t', 'png', tmp_path],
            check=True, timeout=5
        )
        
        with open(tmp_path, 'rb') as f:
            return f.read()
    
    def configure_chat_region(self, x, y, w, h):
        """æ‰‹åŠ¨é…ç½®èŠå¤©åŒºåŸŸåæ ‡ï¼ˆé¦–æ¬¡éƒ¨ç½²æ—¶è®¾ç½®ï¼‰"""
        self._chat_region = (x, y, w, h)


class ImageDiffDetector:
    """
    å›¾åƒå·®å¼‚æ£€æµ‹ â€” æ ¸å¿ƒä¼˜åŒ–ç‚¹
    
    åªæœ‰ç”»é¢çœŸæ­£å˜åŒ–æ—¶æ‰è§¦å‘åç»­ OCR/VLM å¤„ç†
    å®æµ‹å¯è¿‡æ»¤æ‰ 90-95% çš„æ— æ•ˆæˆªå›¾
    """
    
    def __init__(self, threshold=0.02):
        self.threshold = threshold
        self.last_hash = None
        self.last_bottom_pixels = None
    
    def has_changed(self, image_bytes: bytes) -> bool:
        import hashlib
        import numpy as np
        from PIL import Image
        from io import BytesIO
        
        # ç¬¬ä¸€å±‚ï¼šMD5 å¿«é€Ÿæ¯”å¯¹ï¼ˆå®Œå…¨ç›¸åŒçš„å›¾ç›´æ¥è·³è¿‡ï¼‰
        current_hash = hashlib.md5(image_bytes).hexdigest()
        if current_hash == self.last_hash:
            return False
        self.last_hash = current_hash
        
        # ç¬¬äºŒå±‚ï¼šåªæ¯”è¾ƒåº•éƒ¨ 30% åŒºåŸŸçš„åƒç´ å˜åŒ–
        # ï¼ˆæ–°æ¶ˆæ¯å‡ ä¹æ€»æ˜¯å‡ºç°åœ¨èŠå¤©çª—å£åº•éƒ¨ï¼‰
        img = Image.open(BytesIO(image_bytes)).convert('L').resize((400, 300))
        arr = np.array(img, dtype=np.float32) / 255.0
        bottom = arr[210:, :]  # åº•éƒ¨ 30%
        
        if self.last_bottom_pixels is not None:
            if bottom.shape == self.last_bottom_pixels.shape:
                diff = np.mean(np.abs(bottom - self.last_bottom_pixels))
                if diff < self.threshold:
                    self.last_bottom_pixels = bottom
                    return False
        
        self.last_bottom_pixels = bottom
        return True
```

### 2.2 æ¶ˆæ¯æå– â€” å¿«é€Ÿè½¨ï¼ˆApple Vision OCRï¼‰

```python
# apple_vision_ocr.py
"""
åˆ©ç”¨ macOS åŸç”Ÿ Vision Framework åšæœ¬åœ° OCR
é›¶æˆæœ¬ã€æ— ç½‘ç»œä¾èµ–ã€~200ms å“åº”
"""
import subprocess
import json
import tempfile
import os

# é¦–æ¬¡è¿è¡Œæ—¶ç¼–è¯‘ Swift helperï¼ˆä¹‹åå¤ç”¨äºŒè¿›åˆ¶ï¼‰
SWIFT_OCR_SOURCE = r'''
import Foundation
import Vision
import AppKit

let imagePath = CommandLine.arguments[1]
guard let image = NSImage(contentsOfFile: imagePath),
      let tiffData = image.tiffRepresentation,
      let bitmap = NSBitmapImageRep(data: tiffData),
      let cgImage = bitmap.cgImage else {
    print("[]"); exit(1)
}

let semaphore = DispatchSemaphore(value: 0)
var jsonOutput = "[]"

let request = VNRecognizeTextRequest { request, error in
    defer { semaphore.signal() }
    guard let observations = request.results as? [VNRecognizedTextObservation] else { return }
    
    var results: [[String: Any]] = []
    for obs in observations {
        guard let candidate = obs.topCandidates(1).first else { continue }
        let box = obs.boundingBox
        results.append([
            "text": candidate.string,
            "confidence": candidate.confidence,
            "x": box.origin.x,
            "y": 1.0 - box.origin.y - box.height,  // ç¿»è½¬ Y è½´ï¼ˆVision ç”¨å·¦ä¸‹è§’åŸç‚¹ï¼‰
            "width": box.width,
            "height": box.height,
        ])
    }
    
    results.sort { ($0["y"] as! Double) < ($1["y"] as! Double) }
    
    if let data = try? JSONSerialization.data(withJSONObject: results),
       let str = String(data: data, encoding: .utf8) {
        jsonOutput = str
    }
}

request.recognitionLanguages = ["zh-Hans", "zh-Hant", "en"]
request.recognitionLevel = .accurate
request.usesLanguageCorrection = true

try? VNImageRequestHandler(cgImage: cgImage).perform([request])
semaphore.wait(timeout: .now() + 3)
print(jsonOutput)
'''


class AppleVisionOCR:
    """macOS åŸç”Ÿ OCR"""
    
    def __init__(self):
        self._binary_path = '/tmp/_qn_ocr_helper'
        self._ensure_compiled()
    
    def _ensure_compiled(self):
        if os.path.exists(self._binary_path):
            return
        src_path = '/tmp/_qn_ocr_helper.swift'
        with open(src_path, 'w') as f:
            f.write(SWIFT_OCR_SOURCE)
        subprocess.run([
            'swiftc', src_path, '-o', self._binary_path,
            '-framework', 'Vision', '-framework', 'AppKit',
            '-O',  # ä¼˜åŒ–ç¼–è¯‘
        ], check=True, timeout=60)
    
    def recognize(self, image_bytes: bytes) -> list:
        """OCR è¯†åˆ«ï¼Œè¿”å›å¸¦ä½ç½®çš„æ–‡æœ¬å—åˆ—è¡¨"""
        tmp = '/tmp/_qn_ocr_input.png'
        with open(tmp, 'wb') as f:
            f.write(image_bytes)
        
        result = subprocess.run(
            [self._binary_path, tmp],
            capture_output=True, text=True, timeout=5
        )
        
        try:
            return json.loads(result.stdout.strip())
        except (json.JSONDecodeError, ValueError):
            return []
    
    def quick_check_new_text(self, image_bytes: bytes, known_texts: set) -> bool:
        """
        å¿«é€Ÿæ£€æŸ¥æ˜¯å¦æœ‰æ–°æ–‡æœ¬å‡ºç°ï¼ˆä¸åšå®Œæ•´è§£æï¼‰
        ç”¨äºå†³å®šæ˜¯å¦å€¼å¾—è°ƒç”¨ VLM
        """
        blocks = self.recognize(image_bytes)
        for block in blocks:
            text = block.get('text', '')[:25]
            if text and text not in known_texts:
                return True
        return False
```

### 2.3 æ¶ˆæ¯æå– â€” ç²¾å‡†è½¨ï¼ˆVLM è§†è§‰æ¨¡å‹ï¼‰

```python
# vlm_extractor.py
"""
VLMï¼ˆè§†è§‰è¯­è¨€æ¨¡å‹ï¼‰æ¶ˆæ¯æå–å™¨
ç²¾ç¡®æå–èŠå¤©æ¶ˆæ¯çš„å®Œæ•´ç»“æ„ï¼šè°è¯´çš„ã€è¯´äº†ä»€ä¹ˆã€ä»€ä¹ˆæ—¶é—´

æ¨èæ¨¡å‹ä¼˜å…ˆçº§ï¼š
1. Qwen2-VL-72Bï¼ˆé€šä¹‰åƒé—® VL-Maxï¼‰â€” ä¸­æ–‡æœ€ä½³
2. GPT-4o â€” é€šç”¨èƒ½åŠ›å¼º
3. Claude 3.5 Sonnet â€” æŒ‡ä»¤éµå¾ªå¥½
4. Qwen2-VL-7B æœ¬åœ°éƒ¨ç½² â€” é›¶æˆæœ¬ä½†éœ€ GPU
"""
import base64
import json
import httpx
import asyncio
from typing import List, Optional


EXTRACT_PROMPT = """åˆ†æè¿™å¼ å®¢æœèŠå¤©è½¯ä»¶ï¼ˆåƒç‰›æ—ºæ—ºï¼‰çš„æˆªå›¾ï¼Œæå–æ‰€æœ‰å¯è§çš„èŠå¤©æ¶ˆæ¯ã€‚

è§„åˆ™ï¼š
1. ä»”ç»†åŒºåˆ† **ä¹°å®¶æ¶ˆæ¯**ï¼ˆå®¢æˆ·ï¼‰å’Œ **å®¢æœæ¶ˆæ¯**ï¼ˆæˆ‘æ–¹ï¼‰ï¼Œé€šå¸¸é€šè¿‡å¤´åƒä½ç½®ã€æ¶ˆæ¯æ°”æ³¡æ–¹å‘æ¥åˆ¤æ–­
2. æŒ‰ä»ä¸Šåˆ°ä¸‹ï¼ˆæ—¶é—´ä»æ—©åˆ°æ™šï¼‰çš„é¡ºåºæ’åˆ—
3. æå–æ—¶é—´æˆ³ï¼ˆå¦‚æœå¯è§ï¼‰
4. å›¾ç‰‡æ¶ˆæ¯æ ‡è®°ä¸º [å›¾ç‰‡]ï¼Œå•†å“é“¾æ¥æ ‡è®°ä¸º [å•†å“å¡ç‰‡:å•†å“åç§°]
5. å¿½ç•¥ç³»ç»Ÿæç¤ºï¼ˆå¦‚"å¯¹æ–¹æ­£åœ¨è¾“å…¥"ã€"å·²è¯»"ç­‰ï¼‰
6. åªæå–æœ€å/æœ€æ–°çš„ 5-8 æ¡æ¶ˆæ¯å³å¯ï¼ˆè¶Šé è¿‘åº•éƒ¨è¶Šé‡è¦ï¼‰

ä¸¥æ ¼è¿”å› JSON æ•°ç»„ï¼Œæ— ä»»ä½•å…¶ä»–æ–‡å­—ï¼š
[
  {"role": "customer", "text": "æ¶ˆæ¯åŸæ–‡", "time": "HH:MM"},
  {"role": "agent", "text": "æ¶ˆæ¯åŸæ–‡", "time": "HH:MM"}
]"""


class VLMExtractor:
    """VLM æ¶ˆæ¯æå–"""
    
    def __init__(self, provider: str = "qwen", api_key: str = "", model: str = ""):
        self.provider = provider
        self.api_key = api_key
        self.model = model or self._default_model()
        self._client = httpx.AsyncClient(timeout=20)
    
    def _default_model(self):
        return {
            "qwen": "qwen-vl-max",
            "openai": "gpt-4o",
            "anthropic": "claude-sonnet-4-20250514",
        }.get(self.provider, "qwen-vl-max")
    
    async def extract(self, image_bytes: bytes) -> List[dict]:
        """ä»æˆªå›¾ä¸­æå–ç»“æ„åŒ–æ¶ˆæ¯"""
        b64 = base64.b64encode(image_bytes).decode()
        
        if self.provider == "qwen":
            return await self._call_qwen(b64)
        elif self.provider == "openai":
            return await self._call_openai(b64)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„ provider: {self.provider}")
    
    async def _call_qwen(self, b64_image: str) -> List[dict]:
        resp = await self._client.post(
            "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions",
            headers={"Authorization": f"Bearer {self.api_key}"},
            json={
                "model": self.model,
                "messages": [{
                    "role": "user",
                    "content": [
                        {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{b64_image}"}},
                        {"type": "text", "text": EXTRACT_PROMPT},
                    ]
                }],
                "temperature": 0,
                "max_tokens": 2000,
            }
        )
        return self._parse_response(resp.json()['choices'][0]['message']['content'])
    
    async def _call_openai(self, b64_image: str) -> List[dict]:
        resp = await self._client.post(
            "https://api.openai.com/v1/chat/completions",
            headers={"Authorization": f"Bearer {self.api_key}"},
            json={
                "model": self.model,
                "messages": [{
                    "role": "user",
                    "content": [
                        {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{b64_image}"}},
                        {"type": "text", "text": EXTRACT_PROMPT},
                    ]
                }],
                "temperature": 0,
                "max_tokens": 2000,
            }
        )
        return self._parse_response(resp.json()['choices'][0]['message']['content'])
    
    def _parse_response(self, content: str) -> List[dict]:
        content = content.strip()
        if content.startswith('```'):
            content = content.split('\n', 1)[1].rsplit('```', 1)[0]
        try:
            return json.loads(content)
        except json.JSONDecodeError:
            return []
```

### 2.4 ç›‘æ§ä¸»å¾ªç¯

```python
# monitor.py
"""
æ¶ˆæ¯ç›‘æ§ä¸»æ§åˆ¶å™¨
å°†æˆªå›¾ã€å·®å¼‚æ£€æµ‹ã€OCRã€VLM ä¸²è”æˆå®Œæ•´æµæ°´çº¿
"""
import asyncio
import time
import logging
from collections import OrderedDict

logger = logging.getLogger(__name__)


class MessageMonitor:
    """æ¶ˆæ¯ç›‘æ§ä¸»å¾ªç¯"""
    
    def __init__(self, config: dict, on_message_callback):
        self.capture = ScreenCapture()
        self.diff = ImageDiffDetector(threshold=config.get('diff_threshold', 0.02))
        self.ocr = AppleVisionOCR()
        self.vlm = VLMExtractor(
            provider=config.get('vlm_provider', 'qwen'),
            api_key=config['vlm_api_key'],
            model=config.get('vlm_model'),
        )
        self.callback = on_message_callback
        
        self.known_messages = OrderedDict()  # text_hash -> message
        self.ocr_known_texts = set()
        self.poll_interval = config.get('poll_interval', 0.5)
        
        # ç»Ÿè®¡
        self.stats = {'captures': 0, 'diffs': 0, 'vlm_calls': 0, 'messages': 0}
    
    async def run(self):
        """ä¸»ç›‘æ§å¾ªç¯"""
        logger.info("ğŸš€ æ¶ˆæ¯ç›‘æ§å¯åŠ¨")
        
        while True:
            try:
                await self._poll_once()
            except Exception as e:
                logger.error(f"ç›‘æ§å¼‚å¸¸: {e}", exc_info=True)
                await asyncio.sleep(2)
            
            await asyncio.sleep(self.poll_interval)
    
    async def _poll_once(self):
        # 1. æˆªå›¾
        image_bytes = self.capture.capture_chat_region()
        self.stats['captures'] += 1
        
        # 2. åƒç´ å·®å¼‚æ£€æµ‹ï¼ˆ~5msï¼‰
        if not self.diff.has_changed(image_bytes):
            return
        self.stats['diffs'] += 1
        
        # 3. å¿«é€Ÿè½¨ï¼šæœ¬åœ° OCR ç¡®è®¤æœ‰æ–°æ–‡æœ¬ï¼ˆ~200msï¼‰
        has_new = self.ocr.quick_check_new_text(image_bytes, self.ocr_known_texts)
        if not has_new:
            return
        
        # 4. ç²¾å‡†è½¨ï¼šVLM æå–å®Œæ•´æ¶ˆæ¯ç»“æ„ï¼ˆ~1.5sï¼‰
        self.stats['vlm_calls'] += 1
        messages = await self.vlm.extract(image_bytes)
        
        # 5. å»é‡ï¼Œæ‰¾å‡ºæ–°æ¶ˆæ¯
        for msg in messages:
            text = msg.get('text', '')
            key = text[:30]  # ç”¨å‰30å­—ç¬¦åšå»é‡é”®
            
            if key and key not in self.known_messages:
                self.known_messages[key] = msg
                self.ocr_known_texts.add(key[:25])
                
                # åªå…³æ³¨å®¢æˆ·æ¶ˆæ¯ï¼ˆå®¢æœæ¶ˆæ¯æ˜¯æˆ‘ä»¬è‡ªå·±å‘çš„ï¼‰
                if msg.get('role') == 'customer':
                    self.stats['messages'] += 1
                    await self.callback(msg)
        
        # æ§åˆ¶å†…å­˜
        while len(self.known_messages) > 500:
            self.known_messages.popitem(last=False)
        if len(self.ocr_known_texts) > 500:
            self.ocr_known_texts = set(list(self.ocr_known_texts)[-200:])
```

---

## ä¸‰ã€æ¶ˆæ¯å‘é€å±‚

```python
# sender.py
"""
æ¶ˆæ¯å‘é€ â€” é€šè¿‡æ¨¡æ‹Ÿé”®ç›˜è¾“å…¥
å…¼å®¹ macOS å’Œ Windows
"""
import subprocess
import time
import threading

class MessageSender:
    """æ¨¡æ‹Ÿé”®ç›˜è¾“å…¥å‘é€æ¶ˆæ¯"""
    
    def __init__(self):
        self._lock = threading.Lock()
    
    def send(self, text: str, session_id: str = None):
        """
        å‘é€æ¶ˆæ¯åˆ°å½“å‰æ¿€æ´»çš„åƒç‰›èŠå¤©çª—å£
        
        æµç¨‹ï¼š
        1. å¦‚æœéœ€è¦åˆ‡æ¢ä¼šè¯ â†’ ç‚¹å‡»ä¼šè¯åˆ—è¡¨
        2. èšç„¦è¾“å…¥æ¡†
        3. é€šè¿‡å‰ªè´´æ¿ç²˜è´´æ–‡æœ¬ï¼ˆæ”¯æŒä¸­æ–‡ã€è¡¨æƒ…ã€ç‰¹æ®Šå­—ç¬¦ï¼‰
        4. æŒ‰å›è½¦å‘é€
        """
        with self._lock:  # ä¸²è¡ŒåŒ–ï¼Œé˜²æ­¢å¹¶å‘å†²çª
            try:
                if session_id:
                    self._switch_session(session_id)
                    time.sleep(0.15)
                
                self._focus_input_box()
                time.sleep(0.05)
                
                self._paste_text(text)
                time.sleep(0.1)
                
                self._press_enter()
                
            except Exception as e:
                raise RuntimeError(f"å‘é€å¤±è´¥: {e}")
    
    def _paste_text(self, text: str):
        """é€šè¿‡å‰ªè´´æ¿ç²˜è´´ï¼ˆmacOSï¼‰"""
        # å†™å…¥å‰ªè´´æ¿
        process = subprocess.Popen(['pbcopy'], stdin=subprocess.PIPE)
        process.communicate(text.encode('utf-8'))
        
        # Cmd+V ç²˜è´´
        subprocess.run([
            'osascript', '-e',
            'tell application "System Events" to keystroke "v" using command down'
        ], timeout=3)
    
    def _press_enter(self):
        """æŒ‰å›è½¦å‘é€"""
        subprocess.run([
            'osascript', '-e',
            'tell application "System Events" to key code 36'  # Return key
        ], timeout=3)
    
    def _focus_input_box(self):
        """èšç„¦åƒç‰›è¾“å…¥æ¡†ï¼ˆç‚¹å‡»è¾“å…¥åŒºåŸŸï¼‰"""
        # æ–¹å¼1: AppleScript æ¿€æ´»çª—å£
        subprocess.run([
            'osascript', '-e',
            '''tell application "Aliworkbench" to activate'''
        ], timeout=3)
        time.sleep(0.1)
        
        # æ–¹å¼2: ç‚¹å‡»è¾“å…¥åŒºåŸŸï¼ˆéœ€è¦æ ¹æ®å®é™…åæ ‡è°ƒæ•´ï¼‰
        # é€šå¸¸è¾“å…¥æ¡†åœ¨çª—å£åº•éƒ¨ä¸­é—´ä½ç½®
        # subprocess.run([
        #     'osascript', '-e',
        #     'tell application "System Events" to click at {800, 700}'
        # ], timeout=3)
    
    def _switch_session(self, session_id: str):
        """
        åˆ‡æ¢åˆ°æŒ‡å®šä¼šè¯
        
        ç­–ç•¥ï¼šåœ¨åƒç‰›å·¦ä¾§ä¼šè¯åˆ—è¡¨ä¸­æœç´¢/ç‚¹å‡»
        è¿™é‡Œç”¨ AppleScript æˆ–åæ ‡ç‚¹å‡»å®ç°
        """
        # TODO: æ ¹æ®åƒç‰›å®é™…å¸ƒå±€å®ç°ä¼šè¯åˆ‡æ¢
        pass
```

---

## å››ã€äº‘ç«¯ AI å¤„ç†æµæ°´çº¿

```python
# ai_pipeline.py
"""
å®Œæ•´çš„ AI æ¶ˆæ¯å¤„ç†æµæ°´çº¿
æ„å›¾è¯†åˆ« â†’ RAG æ£€ç´¢ â†’ ç­”æ¡ˆç”Ÿæˆ â†’ è´¨é‡æ£€æŸ¥
"""
import asyncio
import json
import time
from typing import List, Dict, Optional


class AIPipeline:
    """AI æ¶ˆæ¯å¤„ç†æµæ°´çº¿"""
    
    def __init__(self, config: dict):
        self.llm_fast = config['llm_fast']     # è½»é‡æ¨¡å‹ï¼ˆæ„å›¾åˆ†ç±»ï¼‰
        self.llm_main = config['llm_main']     # ä¸»åŠ›æ¨¡å‹ï¼ˆç­”æ¡ˆç”Ÿæˆï¼‰
        self.rag = config['rag_engine']         # RAG æ£€ç´¢å¼•æ“
        self.context = config['context_store']  # Redis ä¼šè¯ä¸Šä¸‹æ–‡
    
    async def process(self, session_id: str, customer_msg: str, store_id: str) -> dict:
        """
        å¤„ç†ä¸€æ¡å®¢æˆ·æ¶ˆæ¯
        
        è¿”å›:
        {
            "action": "reply" | "escalate" | "hold",
            "text": "å›å¤å†…å®¹",
            "confidence": 0.92,
            "intent": {"type": "pre_sale", "sub": "price_inquiry"},
            "rag_sources": ["FAQ#23", "äº§å“æ‰‹å†ŒP12"],
        }
        """
        
        # 1. è·å–ä¼šè¯å†å²
        history = await self.context.get_history(session_id, max_turns=8)
        store_config = await self.context.get_store_config(store_id)
        
        # 2. æ„å›¾è¯†åˆ«ï¼ˆè½»é‡æ¨¡å‹ï¼Œ<200msï¼‰
        intent = await self._classify_intent(customer_msg, history)
        
        # 3. ç´§æ€¥/æŠ•è¯‰ â†’ è½¬äººå·¥
        if intent['type'] == 'complaint' and intent.get('confidence', 0) > 0.8:
            return {
                "action": "escalate",
                "reason": "æ£€æµ‹åˆ°æŠ•è¯‰ï¼Œå»ºè®®äººå·¥ä»‹å…¥",
                "intent": intent,
                "suggested_reply": "äº²ï¼Œéå¸¸æŠ±æ­‰ç»™æ‚¨å¸¦æ¥ä¸å¥½çš„ä½“éªŒï¼Œæˆ‘è¿™è¾¹é©¬ä¸Šå¸®æ‚¨å¤„ç†~",
            }
        
        # 4. RAG çŸ¥è¯†æ£€ç´¢
        rag_results = await self.rag.search(
            query=customer_msg,
            category=intent['type'],
            top_k=5,
            score_threshold=0.65,
        )
        
        # 5. çŸ¥è¯†åº“æ— åŒ¹é… â†’ æç¤ºè½¬äººå·¥æˆ–ç”¨é€šç”¨è¯æœ¯
        if not rag_results or rag_results[0]['score'] < 0.6:
            return {
                "action": "escalate",
                "reason": "çŸ¥è¯†åº“æœªæ‰¾åˆ°åŒ¹é…",
                "intent": intent,
                "suggested_reply": "äº²ï¼Œè¿™ä¸ªé—®é¢˜æˆ‘å¸®æ‚¨è½¬æ¥ä¸“ä¸šå®¢æœå¤„ç†å“¦~è¯·ç¨ç­‰",
            }
        
        # 6. ç”Ÿæˆå›å¤
        reply = await self._generate_reply(
            customer_msg, intent, rag_results, history, store_config
        )
        
        # 7. è´¨é‡æ£€æŸ¥
        quality = await self._quality_check(reply, customer_msg, rag_results)
        
        # 8. ä¿å­˜ä¸Šä¸‹æ–‡
        await self.context.add_message(session_id, 'user', customer_msg)
        await self.context.add_message(session_id, 'assistant', reply)
        
        return {
            "action": "reply",
            "text": reply,
            "confidence": quality['confidence'],
            "intent": intent,
            "rag_sources": [r['source'] for r in rag_results[:3]],
            "quality": quality,
        }
    
    async def _classify_intent(self, msg: str, history: list) -> dict:
        """æ„å›¾åˆ†ç±»"""
        prompt = f"""åˆ†æå®¢æˆ·æ¶ˆæ¯æ„å›¾ï¼Œè¿”å›JSONã€‚
        
å¯èƒ½çš„æ„å›¾: pre_sale(å”®å‰), in_sale(å”®ä¸­-ç‰©æµ/è®¢å•), after_sale(å”®å-é€€æ¢/æŠ•è¯‰), greeting(é—®å€™)

å†å²: {json.dumps(history[-4:], ensure_ascii=False)}
å®¢æˆ·: {msg}

è¿”å›: {{"type":"...","sub":"...","confidence":0.95,"entities":{{"product":"","order_id":""}}}}"""
        
        result = await self.llm_fast.complete(prompt, max_tokens=200, temperature=0)
        return json.loads(result)
    
    async def _generate_reply(self, msg, intent, rag, history, config) -> str:
        """ç”Ÿæˆå›å¤"""
        knowledge = "\n".join([f"[{i+1}] {r['content']}" for i, r in enumerate(rag)])
        
        system = f"""ä½ æ˜¯ã€Œ{config['store_name']}ã€çš„ä¸“ä¸šå®¢æœã€‚
ç§°å‘¼: {config.get('greeting', 'äº²')}
è¯­æ°”: {config.get('tone', 'äº²åˆ‡ä¸“ä¸š')}
è¦æ±‚:
- ä¸¥æ ¼åŸºäºçŸ¥è¯†åº“å›ç­”ï¼Œä¸ç¼–é€ ä¿¡æ¯
- å›å¤ç®€æ´ï¼Œä¸è¶…è¿‡{config.get('max_length', 120)}å­—
- ä¸ç¡®å®šæ—¶è¯´"æˆ‘å¸®æ‚¨æ ¸å®ä¸€ä¸‹"
- å”®åé—®é¢˜å…ˆè¡¨è¾¾æ­‰æ„

çŸ¥è¯†åº“:
{knowledge}"""
        
        messages = [{"role": "system", "content": system}]
        for h in history[-6:]:
            messages.append(h)
        messages.append({"role": "user", "content": msg})
        
        return await self.llm_main.chat(messages, temperature=0.3, max_tokens=300)
    
    async def _quality_check(self, reply: str, query: str, rag: list) -> dict:
        """
        å›å¤è´¨é‡æ£€æŸ¥
        - æ˜¯å¦åŸºäºçŸ¥è¯†åº“
        - æ˜¯å¦åŒ…å«æ•æ„Ÿ/ç¦æ­¢å†…å®¹
        - ç½®ä¿¡åº¦è¯„ä¼°
        """
        # ç®€å•è§„åˆ™æ£€æŸ¥
        confidence = 0.85
        issues = []
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç¼–é€ å«Œç–‘ï¼ˆå›å¤ä¸­åŒ…å«çŸ¥è¯†åº“ä¸­æ²¡æœ‰çš„æ•°å­—/ä»·æ ¼ï¼‰
        import re
        reply_numbers = set(re.findall(r'\d+\.?\d*', reply))
        rag_text = ' '.join(r['content'] for r in rag)
        rag_numbers = set(re.findall(r'\d+\.?\d*', rag_text))
        
        suspicious_numbers = reply_numbers - rag_numbers - {'1', '2', '3', '24', '48', '72'}
        if suspicious_numbers:
            confidence -= 0.2
            issues.append(f"å›å¤ä¸­åŒ…å«çŸ¥è¯†åº“æœªå‡ºç°çš„æ•°å­—: {suspicious_numbers}")
        
        # æ•æ„Ÿè¯æ£€æŸ¥
        sensitive_words = ['ç»å¯¹', 'ä¿è¯100%', 'è‚¯å®šä¸ä¼š', 'æ³•å¾‹', 'æŠ•è¯‰å·¥å•†']
        for word in sensitive_words:
            if word in reply:
                confidence -= 0.15
                issues.append(f"åŒ…å«æ•æ„Ÿè¯: {word}")
        
        return {
            "confidence": max(0.1, confidence),
            "issues": issues,
            "pass": confidence >= 0.6,
        }
```

---

## äº”ã€äººæœºåä½œæ¨¡å¼

```python
# collaboration.py
"""
ä¸‰ç§åä½œæ¨¡å¼ï¼Œå¯æŒ‰ä¼šè¯ç²’åº¦å®æ—¶åˆ‡æ¢
"""
from enum import Enum


class Mode(Enum):
    AI_AUTO = "ai_auto"       # AI å…¨æ‰˜ç®¡ï¼šAI ç›´æ¥å›å¤å®¢æˆ·
    AI_ASSIST = "ai_assist"   # AI è¾…åŠ©ï¼šAI å‡ºå»ºè®®ï¼Œäººå·¥å®¡æ ¸
    HUMAN_ONLY = "human_only" # çº¯äººå·¥ï¼šAI åªåšçŸ¥è¯†æ£€ç´¢è¾…åŠ©


class CollaborationController:
    
    async def handle_ai_result(self, session, ai_result):
        """æ ¹æ®ä¼šè¯æ¨¡å¼å¤„ç† AI ç»“æœ"""
        
        if session.mode == Mode.AI_AUTO:
            # å…¨æ‰˜ç®¡ï¼šç½®ä¿¡åº¦å¤Ÿé«˜å°±ç›´æ¥å‘
            if ai_result['confidence'] >= 0.75 and ai_result['action'] == 'reply':
                await self.sender.send(ai_result['text'], session.id)
                await self.log(session.id, 'auto_sent', ai_result)
            else:
                # ç½®ä¿¡åº¦ä¸å¤Ÿï¼Œé™çº§åˆ°è¾…åŠ©æ¨¡å¼
                await self.push_draft_to_console(session.id, ai_result)
        
        elif session.mode == Mode.AI_ASSIST:
            # è¾…åŠ©æ¨¡å¼ï¼šæ¨é€åˆ°æ§åˆ¶å°ï¼Œç­‰äººå·¥æ“ä½œ
            # äººå·¥å¯ä»¥ï¼š[âœ…ç›´æ¥å‘é€] [âœï¸ç¼–è¾‘åå‘é€] [âŒå¿½ç•¥è‡ªè¡Œå›å¤]
            await self.push_draft_to_console(session.id, ai_result)
        
        elif session.mode == Mode.HUMAN_ONLY:
            # çº¯äººå·¥ï¼šåªåœ¨ä¾§è¾¹æ æ˜¾ç¤ºçŸ¥è¯†æ£€ç´¢ç»“æœ
            await self.push_knowledge_hint(session.id, ai_result.get('rag_sources'))
    
    async def auto_switch_rules(self, session, ai_result):
        """è‡ªåŠ¨æ¨¡å¼åˆ‡æ¢è§„åˆ™"""
        
        # è§„åˆ™1ï¼šè¿ç»­ 3 æ¬¡ä½ç½®ä¿¡åº¦ â†’ åˆ‡åˆ°è¾…åŠ©æ¨¡å¼
        if self._low_confidence_streak(session) >= 3:
            session.mode = Mode.AI_ASSIST
        
        # è§„åˆ™2ï¼šæ£€æµ‹åˆ°æ•æ„Ÿè¯ï¼ˆé€€æ¬¾ã€æŠ•è¯‰ã€315ã€å·®è¯„ï¼‰â†’ è½¬äººå·¥
        sensitive = ['é€€æ¬¾', 'æŠ•è¯‰', '315', 'å·®è¯„', 'å·¥å•†', 'æ¶ˆå', 'å¾‹å¸ˆ']
        msg_text = ai_result.get('customer_text', '')
        if any(w in msg_text for w in sensitive):
            session.mode = Mode.HUMAN_ONLY
            await self.alert_human(session.id, f"æ•æ„Ÿè¯è§¦å‘: {msg_text[:50]}")
        
        # è§„åˆ™3ï¼šå®¢æˆ·è¯´"è½¬äººå·¥"/"æ‰¾äººå·¥å®¢æœ" â†’ è½¬äººå·¥
        if any(w in msg_text for w in ['è½¬äººå·¥', 'äººå·¥å®¢æœ', 'æ‰¾ä¸ªäºº', 'ä½ æ˜¯æœºå™¨äºº']):
            session.mode = Mode.HUMAN_ONLY
```

---

## å…­ã€æ€§èƒ½ä¸æˆæœ¬ä¼˜åŒ–

### å…³é”®æ€§èƒ½æŒ‡æ ‡

| ç¯èŠ‚ | è€—æ—¶ | é¢‘ç‡ | è¯´æ˜ |
|------|------|------|------|
| æˆªå›¾ | ~30ms | 2æ¬¡/ç§’ | CoreGraphics API |
| åƒç´ å·®å¼‚æ£€æµ‹ | ~5ms | 2æ¬¡/ç§’ | numpy å‘é‡è®¡ç®— |
| Apple Vision OCR | ~200ms | 0.3æ¬¡/ç§’ | ä»…ç”»é¢å˜åŒ–æ—¶ |
| VLM æå– | ~1.5s | 0.2æ¬¡/ç§’ | ä»…ç¡®è®¤æœ‰æ–°æ¶ˆæ¯æ—¶ |
| AI æ„å›¾åˆ†ç±» | ~200ms | æŒ‰æ¶ˆæ¯è§¦å‘ | è½»é‡æ¨¡å‹ |
| RAG æ£€ç´¢ | ~50ms | æŒ‰æ¶ˆæ¯è§¦å‘ | Qdrant å‘é‡æœç´¢ |
| AI ç­”æ¡ˆç”Ÿæˆ | ~1s | æŒ‰æ¶ˆæ¯è§¦å‘ | ä¸»åŠ›æ¨¡å‹ |
| **ç«¯åˆ°ç«¯æ€»å»¶è¿Ÿ** | **~3s** | | ä»å®¢æˆ·å‘æ¶ˆæ¯åˆ° AI å›å¤ |

### æœˆåº¦æˆæœ¬ä¼°ç®—ï¼ˆ10 åå¸­è§„æ¨¡ï¼‰

```
VLM è°ƒç”¨è´¹ï¼ˆæ¶ˆæ¯æå–ï¼‰:
  VLM è°ƒç”¨é¢‘ç‡: ~0.2æ¬¡/ç§’/åå¸­ Ã— 8å°æ—¶ Ã— 22å¤© = ~12,672 æ¬¡/æœˆ/åå¸­
  10åå¸­: 126,720 æ¬¡/æœˆ
  Qwen-VL-Plus: ~Â¥0.003/åƒtoken Ã— 1500token/æ¬¡ â‰ˆ Â¥570/æœˆ
  
LLM è°ƒç”¨è´¹ï¼ˆæ„å›¾+ç”Ÿæˆï¼‰:
  æ¶ˆæ¯é‡: ~200æ¡/å¤©/åå¸­ Ã— 10åå¸­ Ã— 22å¤© = 44,000 æ¡/æœˆ
  æ„å›¾åˆ†ç±»(qwen-turbo): ~Â¥200/æœˆ
  ç­”æ¡ˆç”Ÿæˆ(qwen-plus): ~Â¥1,500/æœˆ
  Embedding: ~Â¥100/æœˆ
  
çƒ­é—¨é—®é¢˜ç¼“å­˜å‘½ä¸­åå¯å‡å°‘ 30-40% LLM è°ƒç”¨
  
äº‘æœåŠ¡å™¨:
  2å° 4C8Gï¼ˆAI Worker + Gatewayï¼‰: Â¥1,200/æœˆ
  1å° 2C4Gï¼ˆRedis + Qdrant + PGï¼‰: Â¥400/æœˆ

æ€»è®¡: çº¦ Â¥4,000-5,000/æœˆï¼ˆ10åå¸­ï¼‰
å•åå¸­: Â¥400-500/æœˆï¼ˆè¿œä½äºäººå·¥å®¢æœ Â¥4,000-8,000/æœˆï¼‰
```

---

## ä¸ƒã€éƒ¨ç½²ä¸è¿ç»´

### æœ¬åœ° Agent æ‰“åŒ…

```bash
# macOS: ä½¿ç”¨ PyInstaller æ‰“åŒ…
pip install pyinstaller pyobjc-framework-Quartz pyobjc-framework-Vision
pyinstaller --onefile --windowed \
    --add-data "ocr_helper.swift:." \
    --name "QianniuAI-Agent" \
    agent_main.py

# é¦–æ¬¡å®‰è£…éœ€æˆæƒï¼š
# ç³»ç»Ÿè®¾ç½® â†’ éšç§ä¸å®‰å…¨ â†’ å±å¹•å½•åˆ¶ â†’ å…è®¸ QianniuAI-Agent
# ç³»ç»Ÿè®¾ç½® â†’ éšç§ä¸å®‰å…¨ â†’ è¾…åŠ©åŠŸèƒ½ â†’ å…è®¸ QianniuAI-Agent
```

### å…³é”®é…ç½®æ–‡ä»¶

```yaml
# agent_config.yaml
agent:
  poll_interval: 0.5        # æˆªå›¾é—´éš”ï¼ˆç§’ï¼‰
  diff_threshold: 0.02      # åƒç´ å·®å¼‚é˜ˆå€¼
  
chat_region:                 # åƒç‰›èŠå¤©åŒºåŸŸåæ ‡ï¼ˆé¦–æ¬¡éƒ¨ç½²æ—¶æ ¡å‡†ï¼‰
  auto_detect: true          # è‡ªåŠ¨æ£€æµ‹
  # æ‰‹åŠ¨è¦†ç›–:
  # x: 450
  # y: 50
  # width: 800
  # height: 600

vlm:
  provider: qwen             # qwen / openai
  model: qwen-vl-plus        # ç”¨ plus è€Œä¸æ˜¯ maxï¼Œæ€§ä»·æ¯”æ›´é«˜
  api_key: ${VLM_API_KEY}

server:
  url: wss://your-server.com/agent
  reconnect_interval: 5

collaboration:
  default_mode: ai_assist    # é»˜è®¤è¾…åŠ©æ¨¡å¼ï¼Œç¨³å®šååˆ‡å…¨æ‰˜ç®¡
  auto_send_threshold: 0.80  # å…¨æ‰˜ç®¡æ¨¡å¼ä¸‹è‡ªåŠ¨å‘é€çš„ç½®ä¿¡åº¦é˜ˆå€¼
  
safety:
  max_auto_replies_per_session: 10  # å•ä¼šè¯æœ€å¤šè¿ç»­è‡ªåŠ¨å›å¤æ¬¡æ•°
  sensitive_words:                   # è§¦å‘è½¬äººå·¥çš„æ•æ„Ÿè¯
    - é€€æ¬¾
    - æŠ•è¯‰
    - å·®è¯„
    - 315
    - å·¥å•†
```

---

## å…«ã€å®æ–½è·¯çº¿

```
Week 1-2: MVP
â”œâ”€â”€ macOS æˆªå›¾ + å·®å¼‚æ£€æµ‹
â”œâ”€â”€ Apple Vision OCR å¿«é€Ÿè½¨
â”œâ”€â”€ VLM ç²¾å‡†è½¨ï¼ˆQwen-VL-Plusï¼‰
â”œâ”€â”€ åŸºç¡€ AI é—®ç­”ï¼ˆå•è½®ï¼‰
â””â”€â”€ AI è¾…åŠ©æ¨¡å¼ï¼ˆäººå·¥å®¡æ ¸å‘é€ï¼‰

Week 3-4: æ ¸å¿ƒåŠŸèƒ½
â”œâ”€â”€ å¤šè½®å¯¹è¯ä¸Šä¸‹æ–‡
â”œâ”€â”€ RAG çŸ¥è¯†åº“æ­å»º
â”œâ”€â”€ æ„å›¾åˆ†ç±» + æ™ºèƒ½è·¯ç”±
â”œâ”€â”€ äººæœºåä½œæ§åˆ¶å° Web UI
â””â”€â”€ AI å…¨æ‰˜ç®¡æ¨¡å¼

Week 5-6: ç¨³å®šæ€§
â”œâ”€â”€ çƒ­é—¨é—®é¢˜ç¼“å­˜
â”œâ”€â”€ é™çº§ç­–ç•¥ï¼ˆVLM ä¸å¯ç”¨ â†’ çº¯ OCRï¼‰
â”œâ”€â”€ ç›‘æ§å‘Šè­¦
â”œâ”€â”€ å¤šåå¸­æ”¯æŒ
â””â”€â”€ åƒç‰›çª—å£å¼‚å¸¸è‡ªåŠ¨æ¢å¤

Week 7+: ä¼˜åŒ–è¿­ä»£
â”œâ”€â”€ ä»ä¼˜ç§€å®¢æœå¯¹è¯è‡ªåŠ¨å­¦ä¹ 
â”œâ”€â”€ çŸ¥è¯†åº“è‡ªåŠ¨æ›´æ–°
â”œâ”€â”€ A/B æµ‹è¯•æ¡†æ¶
â”œâ”€â”€ æ•°æ®åˆ†æçœ‹æ¿
â””â”€â”€ Windows å¹³å°é€‚é…
```
